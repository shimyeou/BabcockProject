{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feaa847f-c5f6-4df6-a16f-faeb0383e867",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c22729c-524b-4c9d-b552-d713a89628d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9bf1ec-7b66-4e15-b701-568241b85e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4756e295-3afb-426f-89dc-441b6b745763",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f64dc4-c21b-4f58-a105-0c25a0bdc461",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2884d949-aec4-45cc-8b82-5a7a962ceabd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\yeou1\\anaconda3\\envs\\mediapipe-env\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from deepface import DeepFace\n",
    "import os\n",
    "import time\n",
    "from scipy.spatial import distance as dist\n",
    "from imutils.video import VideoStream\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22276b45-9391-4a5f-bd1c-87cf0f5d143d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize MediaPipe Face Mesh\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "\n",
    "# Constants\n",
    "EYE_AR_THRESH = 0.3            # Adjust the eye closed state to trigger the alert \n",
    "EYE_AR_CONSEC_FRAMES = 15      # Adjust amount of eye closed frames to trigger alert\n",
    "MAR_THRESH = 0.09              # Adjust the mouth opened state to trigger the alert \n",
    "MAR_CONSEC_FRAMES = 15         # Adjust amount of mouth opened frames to trigger alert\n",
    "FRAME_SKIP = 2\n",
    "DEEPFACE_CHECK_INTERVAL = 300  # every 300 frames (~10 seconds at 30fps)\n",
    "\n",
    "# Counters and flags\n",
    "frame_count = 0\n",
    "COUNTER = 0\n",
    "MAR_COUNTER = 0\n",
    "ALARM_ON = False\n",
    "yawn_alarm_on = False\n",
    "\n",
    "# Log counters and timestamps\n",
    "drowsiness_log = []\n",
    "yawning_log = []\n",
    "current_name = \"Unknown\"\n",
    "\n",
    "# EAR Calculation\n",
    "def eye_aspect_ratio(eye):\n",
    "    A = dist.euclidean(eye[1], eye[5])\n",
    "    B = dist.euclidean(eye[2], eye[4])\n",
    "    C = dist.euclidean(eye[0], eye[3])\n",
    "    ear = (A + B) / (2.0 * C)\n",
    "    return ear\n",
    "\n",
    "# MAR Calculation\n",
    "def mouth_aspect_ratio(mouth):\n",
    "    A = dist.euclidean(mouth[0], mouth[1])\n",
    "    return A\n",
    "\n",
    "# Start video stream\n",
    "vs = VideoStream(src=0).start()\n",
    "time.sleep(1.0)\n",
    "\n",
    "while True:\n",
    "    frame = vs.read()\n",
    "    frame_count += 1\n",
    "    if frame_count % FRAME_SKIP != 0:\n",
    "        continue\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    frame = cv2.resize(frame, (720, 480))\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Face recognition using DeepFace every 300 frames\n",
    "    if frame_count % DEEPFACE_CHECK_INTERVAL == 0:\n",
    "        try:\n",
    "            bgr_frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "            result = DeepFace.find(\n",
    "                img_path=bgr_frame,\n",
    "                db_path=\"known_faces\",\n",
    "                model_name=\"Facenet\",\n",
    "                distance_metric=\"cosine\",\n",
    "                enforce_detection=False,\n",
    "                silent=True,\n",
    "                threshold=0.6\n",
    "            )\n",
    "\n",
    "            if len(result) > 0 and len(result[0]) > 0:\n",
    "                identity = os.path.basename(result[0].iloc[0]['identity'])\n",
    "                current_name = os.path.splitext(identity)[0]\n",
    "                # Match found (silent)\n",
    "            else:\n",
    "                current_name = \"Unknown\"\n",
    "                # No match found (silent)\n",
    "\n",
    "        except Exception:\n",
    "            current_name = \"Unknown\"\n",
    "            # Face recognition failed (silent)\n",
    "\n",
    "    # MediaPipe facial landmarks\n",
    "    results = face_mesh.process(rgb_frame)\n",
    "\n",
    "    if results.multi_face_landmarks:\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            landmarks = face_landmarks.landmark\n",
    "\n",
    "            left_eye_idx = [33, 160, 158, 133, 153, 144]\n",
    "            right_eye_idx = [263, 387, 385, 362, 380, 373]\n",
    "            mouth_idx = [13, 14]\n",
    "\n",
    "            leftEye = np.array([(landmarks[i].x, landmarks[i].y) for i in left_eye_idx])\n",
    "            rightEye = np.array([(landmarks[i].x, landmarks[i].y) for i in right_eye_idx])\n",
    "            mouth = np.array([(landmarks[i].x, landmarks[i].y) for i in mouth_idx])\n",
    "\n",
    "            leftEAR = eye_aspect_ratio(leftEye)\n",
    "            rightEAR = eye_aspect_ratio(rightEye)\n",
    "            ear = (leftEAR + rightEAR) / 2.0\n",
    "            mar = mouth_aspect_ratio(mouth)\n",
    "\n",
    "            warning_text_1 = \"\"\n",
    "            warning_text_2 = \"\"\n",
    "\n",
    "            if ear < EYE_AR_THRESH:\n",
    "                COUNTER += 1\n",
    "                if COUNTER == EYE_AR_CONSEC_FRAMES:\n",
    "                    ALARM_ON = True\n",
    "                    drowsiness_log.append((time.strftime(\"%Y-%m-%d %H:%M:%S\"), current_name))\n",
    "                    warning_text_1 = \"DROWSINESS ALERT!\"\n",
    "                elif COUNTER > EYE_AR_CONSEC_FRAMES:\n",
    "                    warning_text_1 = \"DROWSINESS ALERT!\"\n",
    "            else:\n",
    "                COUNTER = 0\n",
    "                ALARM_ON = False\n",
    "\n",
    "            if mar > MAR_THRESH:\n",
    "                MAR_COUNTER += 1\n",
    "                if MAR_COUNTER == MAR_CONSEC_FRAMES:\n",
    "                    yawn_alarm_on = True\n",
    "                    yawning_log.append((time.strftime(\"%Y-%m-%d %H:%M:%S\"), current_name))\n",
    "                    warning_text_2 = \"YAWNING DETECTED!\"\n",
    "                elif MAR_COUNTER > MAR_CONSEC_FRAMES:\n",
    "                    warning_text_2 = \"YAWNING DETECTED!\"\n",
    "            else:\n",
    "                MAR_COUNTER = 0\n",
    "                yawn_alarm_on = False\n",
    "\n",
    "            if warning_text_1:\n",
    "                cv2.putText(frame, warning_text_1, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "            if warning_text_2:\n",
    "                cv2.putText(frame, warning_text_2, (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "\n",
    "            cv2.putText(frame, f\"EAR: {ear:.2f}\", (600, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f\"MAR: {mar:.2f}\", (600, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "\n",
    "    # Show current recognized name with color based on match status\n",
    "    name_color = (0, 255, 0) if current_name != \"Unknown\" else (0, 0, 255)\n",
    "    cv2.putText(frame, current_name, (300, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, name_color, 2)\n",
    "\n",
    "    cv2.imshow(\"Fatigue Detection\", frame)\n",
    "    if cv2.waitKey(5) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "# Create and save report\n",
    "\n",
    "# Generate timestamp string\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "save_dir = \"C:/Users/yeou1/Fatigue_project/Reports\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "log_filename = os.path.join(save_dir, f\"fatigue_log_{timestamp}.xlsx\")\n",
    "dashboard_filename = os.path.join(save_dir, f\"fatigue_dashboard_{timestamp}.xlsx\")\n",
    "fatigue_plot_path = os.path.join(save_dir, \"fatigue_plot.png\")\n",
    "fatigue_time_plot_path = os.path.join(save_dir, \"fatigue_time_plot.png\")\n",
    "\n",
    "\n",
    "data = {\n",
    "    \"timestamp\": [ts for ts, _ in drowsiness_log + yawning_log],\n",
    "    \"person\": [name for _, name in drowsiness_log + yawning_log],\n",
    "    \"event\": [\"Drowsiness Alert\"] * len(drowsiness_log) + [\"Yawning Alert\"] * len(yawning_log)\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df.to_excel(log_filename, index=False)\n",
    "\n",
    "# Create and save plot\n",
    "counts = df['event'].value_counts()\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.barplot(x=counts.index, y=counts.values, hue=counts.index, palette=\"pastel\", legend=False)\n",
    "plt.title('Fatigue Event Counts')\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('Event Type')\n",
    "plt.tight_layout()\n",
    "plt.savefig(fatigue_plot_path) \n",
    "plt.close()\n",
    "\n",
    "# Plotting\n",
    "# Convert timestamp column to datetime if not already\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "# Round timestamps to the nearest minute for grouping (or use .dt.floor('10s') for 10-sec bins)\n",
    "df['minute'] = df['timestamp'].dt.floor('T')\n",
    "\n",
    "# Group by time and event\n",
    "time_counts = df.groupby(['minute', 'event']).size().reset_index(name='count')\n",
    "\n",
    "# Create bar plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(data=time_counts, x='minute', y='count', hue='event', palette=\"Set2\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Fatigue Events Over Time')\n",
    "plt.ylabel('Event Count')\n",
    "plt.xlabel('Time')\n",
    "plt.tight_layout()\n",
    "plt.savefig(fatigue_time_plot_path) \n",
    "plt.close()\n",
    "\n",
    "# Save Excel dashboard with embedded plot\n",
    "with pd.ExcelWriter(dashboard_filename, engine='xlsxwriter') as writer:\n",
    "    df.to_excel(writer, sheet_name='Data', index=False)\n",
    "    workbook = writer.book\n",
    "    worksheet = workbook.add_worksheet('Dashboard')\n",
    "    worksheet.insert_image('B2', fatigue_plot_path)\n",
    "    worksheet.insert_image('B22', fatigue_time_plot_path)\n",
    "\n",
    "vs.stream.release()\n",
    "vs.stop()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9084d3-59a6-4f23-8976-4055aca197b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
